{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca04a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Tesis\\REPO\\Cloud-Classification\\code\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96608d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bcbb0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d2584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4195d571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from src import config\n",
    "from src import engine\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5162d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recipe.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba9fced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe82cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(7)\n",
    "np.random.seed(7)\n",
    "random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad09639",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "408d17b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(paths):\n",
    "        return list(map(int,list(map(int,[os.path.basename(x).split('_')[0] \n",
    "                                          for x in paths]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3905beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_paths(df, n=2, col='target', random_state = 7):\n",
    "    \n",
    "    paths = list()\n",
    "    \n",
    "    for key, sub_df in df.groupby(col):\n",
    "        paths+= sub_df.sample(n=n, random_state=random_state)['path'].tolist()\n",
    "        \n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e006ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c81e65c",
   "metadata": {},
   "source": [
    "# 1. Leer df train y funcion de sampleo por clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a0b036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = utils.get_gcd_paths('D:\\Tesis\\REPO','train')\n",
    "targets = get_targets(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83ed0a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({'path':paths, 'target':targets})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48322fdd",
   "metadata": {},
   "source": [
    "# 2. Inferencia en batch de test con distintos pivots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931f16c2",
   "metadata": {},
   "source": [
    "## 2.1 test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74463fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_images = utils.get_gcd_paths('D:\\Tesis\\REPO','test')\n",
    "\n",
    "test_dataset = GCD(path_test_images, resize=256)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        num_workers=8,\n",
    "        shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71d070b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9010"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf205ad7",
   "metadata": {},
   "source": [
    "## 2.2 Construir grafo con imagenes pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c7db56f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphClassifier(\n",
       "  (cnn): CNNExtractor(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (graphconv): GraphLayers(\n",
       "    (conv): GraphConv(in=2048, out=512, normalization=both, activation=None)\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cuda'\n",
    "\n",
    "model = GraphClassifier(7).to(device)\n",
    "model.load_state_dict(torch.load(f'recipe/graph_params_AUGMENTATION.pt', map_location = 'cuda'))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d723b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pivot_deep_features(train_paths, model, device):\n",
    "    \n",
    "    ## 1. train data loader\n",
    "    pivot_dataset = GCD(train_paths, resize=256)\n",
    "    pivot_loader = torch.utils.data.DataLoader(\n",
    "            pivot_dataset,\n",
    "            batch_size=32,\n",
    "            num_workers=8,\n",
    "            shuffle=False,\n",
    "        )\n",
    "    \n",
    "    \n",
    "    ## 2. Append deep features\n",
    "    pivot_features = list()\n",
    "        \n",
    "    for data in pivot_loader:\n",
    "        with torch.no_grad():\n",
    "            deep_features = model.get_deep_features(data['images'].to(device)).cpu()\n",
    "            pivot_features.append(deep_features)\n",
    "        \n",
    "    return torch.cat(pivot_features, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7b8b08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_paths = sample_paths(df_train, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "581f5449",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_features = get_pivot_deep_features(pivot_paths, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "688c2453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2048])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4446af8c",
   "metadata": {},
   "source": [
    "## evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fc670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Reading pivot paths\n",
      "2. Calculating pivot deep features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('1. Reading pivot paths')\n",
    "pivot_paths = sample_paths(df_train, n=8, random_state=10)\n",
    "\n",
    "# pivot_paths = [\n",
    "#     'D:\\\\Tesis\\\\REPO\\\\GCD/train/1_cumulus/1_cumulus_000082.jpg',\n",
    "#     'D:\\\\Tesis\\\\REPO\\\\GCD/train/1_cumulus/1_cumulus_000127.jpg',\n",
    "#     'D:\\\\Tesis\\\\REPO\\\\GCD/train/2_altocumulus/2_altocumulus_000003.jpg',\n",
    "#     'D:\\\\Tesis\\\\REPO\\\\GCD/train/2_altocumulus/2_altocumulus_000028.jpg',\n",
    "#     'D:\\\\Tesis\\\\REPO\\\\GCD/train/3_cirrus/3_cirrus_000035.jpg',\n",
    "#     'D:\\\\Tesis\\\\REPO\\\\GCD/train/3_cirrus/3_cirrus_000115.jpg',\n",
    "#     'D:\\\\Tesis\\\\REPO\\\\GCD/train/4_clearsky/4_clearsky_000004.jpg',\n",
    "#     'D:\\\\Tesis\\\\REPO\\\\GCD/train/4_clearsky/4_clearsky_000055.jpg',\n",
    "#     'D:\\\\Tesis\\\\REPO\\\\GCD/train/5_stratocumulus/5_stratocumulus_000003.jpg',\n",
    "#     'D:\\\\Tesis\\\\REPO\\\\GCD/train/5_stratocumulus/5_stratocumulus_000069.jpg',\n",
    "#     'D:\\\\Tesis\\\\REPO\\\\GCD/train/6_cumulonimbus/6_cumulonimbus_000011.jpg',\n",
    "#     'D:\\\\Tesis\\\\REPO\\\\GCD/train/6_cumulonimbus/6_cumulonimbus_000059.jpg',\n",
    "#     'D:\\\\Tesis\\\\REPO\\\\GCD/train/7_mixed/7_mixed_000006.jpg',\n",
    "#     'D:\\\\Tesis\\\\REPO\\\\GCD/train/7_mixed/7_mixed_000039.jpg',\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "print('2. Calculating pivot deep features')\n",
    "pivot_features = get_pivot_deep_features(pivot_paths, model, device)\n",
    "\n",
    "\n",
    "test_targets = list()\n",
    "test_predictions = list()\n",
    "\n",
    "print('3. Calculating predictions')\n",
    "for data in tqdm(test_loader):\n",
    "    pred_img = data['images']\n",
    "    \n",
    "    pred_feature = model.get_deep_features(pred_img.to(device)).cpu()\n",
    "    \n",
    "    #print((torch.cat([pivot_features, pred_feature], dim=0)[-1] == pred_feature).all())\n",
    "    \n",
    "    pred_images = torch.cat([pivot_features, pred_feature], dim=0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = torch.argmax(F.softmax(model.message_passing(pred_images).cpu(),dim=1), dim=1)\n",
    "        #print(preds.shape)\n",
    "        #print(preds[-1].item())\n",
    "        #print(data['targets'].item())\n",
    "        \n",
    "        test_predictions.append(preds[-1].item())\n",
    "        test_targets.append(data['targets'].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e25a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a13d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_targets, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d976ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array(test_targets)[(np.array(test_targets) == np.array(test_predictions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcea497",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(r).value_counts()/pd.Series(np.array(test_targets)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162153ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
