{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4ab20fe-a684-42d8-83a3-388740455729",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a8dd8b4-6ef4-45a2-9d91-6e835e2191d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda5cd60-9a30-4b34-a07f-2a282deedd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import dataset\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdc2a30f-fb77-4de6-836f-99bd32a2d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ee73518-30fa-4675-a619-c171277a77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/data/ltorres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cbe39fd-479b-4ea7-889c-adc66d1f0df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = utils.get_gcd_paths(DATA_DIR, 'train')\n",
    "test_paths = utils.get_gcd_paths(DATA_DIR, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d62fa9b-f1e4-40c5-9ab0-bdc9dcdb0426",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.GCD(train_paths, resize=224, use_augmentation=True)\n",
    "test_dataset = dataset.GCD(test_paths, resize=224, use_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce049e1a-7579-4466-a789-78afdd8e17a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = utils.build_data_loader(train_dataset, 32, shuffle=True)\n",
    "test_loader = utils.build_data_loader(test_dataset, 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb24187-4605-4ee3-a267-1f09b406fac4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e15fba2f-7960-43c9-8214-4d7622bb6731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.graph_modules import GraphClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0191997-9d4e-41f8-8b1e-e60c85097f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:3'\n",
    "EPOCHS = 4\n",
    "LR = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "700221cb-bd62-4198-9764-07ba56b9df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphClassifier(\n",
    "                 hidden_dim = 512, \n",
    "                 num_hidden = 2, \n",
    "                 num_classes = 7,\n",
    "                 conv_type = 'gat',\n",
    "                 conv_parameters = {'num_heads':4, 'residual': False, 'agg':'sum'},\n",
    "                 adjacency_builder = 'cos_sim',\n",
    "                 builder_parameter = 0.7,\n",
    "                 use_both_heads = False,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdf4afbc-c24e-4a6a-af7c-14278413756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "067bdd56-345a-4782-8ca8-ceee019309b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_params = dict()\n",
    "crit_params[\"hyperparameters\"] = dict()\n",
    "crit_params[\"model\"] = dict()\n",
    "crit_params[\"hyperparameters\"][\"criterion\"] = 'cross_entropy'\n",
    "crit_params[\"model\"][\"use_both_heads\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "434d804f-e179-4bb7-a71a-011937376cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_params = dict()\n",
    "optim_params[\"hyperparameters\"] = dict()\n",
    "optim_params[\"hyperparameters\"][\"optimizer\"] = 'adam'\n",
    "optim_params[\"hyperparameters\"][\"learning_rate\"] = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c4cd6a56-6199-4413-8e90-4c83ceb20113",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.graph_layers[0].conv.fc.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6dd00849-0225-48ae-b611-4bb297949d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "789cd0e4-7ab2-4f76-b28e-8244d2c32204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 GraphAttentionLayer(\n",
      "  (conv): GATConv(\n",
      "    (fc): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "    (feat_drop): Dropout(p=False, inplace=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      ")\n",
      "0\n",
      "1 GraphAttentionLayer(\n",
      "  (conv): GATConv(\n",
      "    (fc): Linear(in_features=512, out_features=2048, bias=False)\n",
      "    (feat_drop): Dropout(p=False, inplace=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "log_l, log_r = model(batch['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bbbf8a61-3e05-47b2-a28d-fa2d53581180",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterions = utils.build_criterions(crit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "98204263-f7b6-4a77-bd72-feddc9a558dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterions['main_head'](log_l, batch['targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7846c700-a9ca-41db-ad9e-570cb72f5109",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.graph_layers[0].conv.fc.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "eed6fd88-140e-4772-aa86-c1140ad34e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bc76c1ca-46fa-4767-a655-07aeeb2c4527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.9534e-04, -2.6134e-03, -7.0916e-04,  ..., -2.2554e-03,\n",
       "         -7.7730e-04, -2.6412e-05],\n",
       "        [-3.0287e-03,  1.5719e-03,  5.2376e-03,  ...,  1.0080e-02,\n",
       "          9.7355e-03, -5.3214e-03],\n",
       "        [-6.8972e-03, -1.0852e-02, -1.0257e-02,  ..., -5.8926e-03,\n",
       "         -1.1089e-02, -1.0731e-02],\n",
       "        ...,\n",
       "        [-9.8936e-04, -4.6764e-03, -2.6021e-03,  ..., -3.9911e-03,\n",
       "         -2.2486e-03, -1.8864e-04],\n",
       "        [ 2.9293e-04,  8.3049e-04,  5.8094e-04,  ...,  4.5014e-04,\n",
       "          1.0384e-03,  8.6720e-04],\n",
       "        [ 2.5062e-02,  3.5373e-02,  3.1972e-02,  ...,  1.8586e-02,\n",
       "          2.8183e-02,  2.2588e-02]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.graph_layers[0].conv.fc.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "534d004e-a830-417e-a0da-15ba3b193341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:45<00:00,  2.97it/s]\n",
      "100%|██████████| 282/282 [00:41<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1: Train acc: 43.42% Train Loss: 0.8426 Test acc: 136.78% Test Loss: 0.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/313 [00:02<02:26,  2.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m best_accuracy\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 8\u001b[0m     train_loss, train_acc, train_targets, train_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                                                    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                                                                    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                                                                    \u001b[49m\u001b[43mcriterions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                                                                    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                                                                    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                                                                    \u001b[49m\u001b[43muse_both_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                                                                    \u001b[49m\u001b[43mloss_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                                                      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     test_loss, test_acc, test_targets, test_predictions \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mtest_model(\n\u001b[1;32m     19\u001b[0m                                                                                 model, \n\u001b[1;32m     20\u001b[0m                                                                                 test_loader, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                                                 loss_lambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     25\u001b[0m                                                                   )\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m#train_acc = accuracy_score(train_targets, train_predictions)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m#test_acc = accuracy_score(test_targets, test_predictions)\u001b[39;00m\n",
      "File \u001b[0;32m~/leo/Cloud-Classification/cloud_classification/src/utils.py:193\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, data_loader, criterions, optimizer, device, use_both_heads, loss_lambda)\u001b[0m\n\u001b[1;32m    188\u001b[0m         data[k] \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    191\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 193\u001b[0m logits_main_head, logits_second_head \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_both_heads:\n\u001b[1;32m    196\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_head\u001b[39m\u001b[38;5;124m\"\u001b[39m](logits_main_head, data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m+\u001b[39m loss_lambda\u001b[38;5;241m*\u001b[39mcriterions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecond_head\u001b[39m\u001b[38;5;124m\"\u001b[39m](logits_second_head, data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/leo/Cloud-Classification/cloud_classification/src/modules/graph_modules.py:163\u001b[0m, in \u001b[0;36mGraphClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    160\u001b[0m x \u001b[38;5;241m=\u001b[39m deep_features\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, gnn_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_layers):\n\u001b[0;32m--> 163\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mgnn_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_layers)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    165\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(x)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/leo/Cloud-Classification/cloud_classification/src/modules/graph_modules.py:60\u001b[0m, in \u001b[0;36mGraphConvLayer.forward\u001b[0;34m(self, g, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, g, x):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/dgl/nn/pytorch/conv/graphconv.py:382\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mlocal_scope():\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_zero_in_degree:\n\u001b[0;32m--> 382\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_degrees\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    383\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DGLError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThere are 0-in-degree nodes in the graph, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    384\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput for those nodes will be invalid. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    385\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis is harmful for some applications, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto be `True` when constructing this module will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    391\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuppress the check and let the code run.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    392\u001b[0m     aggregate_fn \u001b[38;5;241m=\u001b[39m fn\u001b[38;5;241m.\u001b[39mcopy_src(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/dgl/heterograph.py:3504\u001b[0m, in \u001b[0;36mDGLHeteroGraph.in_degrees\u001b[0;34m(self, v, etype)\u001b[0m\n\u001b[1;32m   3502\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdstnodes(dsttype)\n\u001b[1;32m   3503\u001b[0m v_tensor \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mprepare_tensor(\u001b[38;5;28mself\u001b[39m, v, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3504\u001b[0m deg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_degrees\u001b[49m\u001b[43m(\u001b[49m\u001b[43metid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[1;32m   3506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mas_scalar(deg)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/dgl/heterograph_index.py:616\u001b[0m, in \u001b[0;36mHeteroGraphIndex.in_degrees\u001b[0;34m(self, etype, v)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21min_degrees\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, v):\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the in degrees of the nodes.\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m    Assume that node_type(v) == dst_type(etype). Thus, the ntype argument is omitted.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03m        The in degree array.\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mfrom_dgl_nd(\u001b[43m_CAPI_DGLHeteroInDegrees\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dgl_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterions = utils.build_criterions(crit_params)\n",
    "optimizer = utils.build_optimizer(model, optim_params)\n",
    "\n",
    "best_accuracy=0\n",
    "\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    train_loss, train_acc, train_targets, train_predictions = utils.train_model(\n",
    "                                                                                    model, \n",
    "                                                                                    train_loader, \n",
    "                                                                                    criterions, \n",
    "                                                                                    optimizer, \n",
    "                                                                                    device, \n",
    "                                                                                    use_both_heads=False,\n",
    "                                                                                    loss_lambda=1,\n",
    "                                                                      )\n",
    "    \n",
    "    test_loss, test_acc, test_targets, test_predictions = utils.test_model(\n",
    "                                                                                model, \n",
    "                                                                                test_loader, \n",
    "                                                                                criterions, \n",
    "                                                                                device, \n",
    "                                                                                use_both_heads=False,\n",
    "                                                                                loss_lambda=1,\n",
    "                                                                  )\n",
    "    \n",
    "    \n",
    "    #train_acc = accuracy_score(train_targets, train_predictions)\n",
    "    #test_acc = accuracy_score(test_targets, test_predictions)\n",
    "    \n",
    "\n",
    "    print(\"EPOCH {}: Train acc: {:.2%} Train Loss: {:.4f} Test acc: {:.2%} Test Loss: {:.4f}\".format( \n",
    "        e+1,\n",
    "        train_acc,\n",
    "        train_loss,\n",
    "        test_acc,\n",
    "        test_loss\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2781aac-8b3c-4fb4-bf1e-17fa658dc3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa74526a-977c-4505-aebb-9252058e9ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.578209</td>\n",
       "      <td>0.804400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0.920734</td>\n",
       "      <td>0.701222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>0.406027</td>\n",
       "      <td>0.846400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941821</td>\n",
       "      <td>0.732333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.579615</td>\n",
       "      <td>0.804300</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1.206249</td>\n",
       "      <td>0.686889</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>0.406273</td>\n",
       "      <td>0.848600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>0.933441</td>\n",
       "      <td>0.715111</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type  epoch      loss  accuracy  experiment\n",
       "0  train      1  0.578209  0.804400           1\n",
       "1   test      1  0.920734  0.701222           1\n",
       "2  train      2  0.406027  0.846400           1\n",
       "3   test      2  0.941821  0.732333           1\n",
       "4  train      1  0.579615  0.804300           2\n",
       "5   test      1  1.206249  0.686889           2\n",
       "6  train      2  0.406273  0.848600           2\n",
       "7   test      2  0.933441  0.715111           2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"/data/ltorres/model_logs/wandb_33ei64m2_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bf00ee00-8b95-40ed-8383-80feafedf61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[1,1], [1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "60c989ba-84f4-4da5-9a52-08ad7ead1dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_matrix_density(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc73d1-c266-452c-9abb-09c64b0b105f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
