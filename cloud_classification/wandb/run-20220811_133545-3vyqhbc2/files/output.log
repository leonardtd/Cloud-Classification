
  0%|                                                                                                       | 0/500 [00:00<?, ?it/s]
GraphClassifier(
  (cnn): CNNExtractor(
    (cnn): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (8): AdaptiveAvgPool2d(output_size=(1, 1))
    )
  )
  (graph_layers): ModuleList(
    (0): GraphConvLayer(
      (conv): GraphConv(in=2048, out=512, normalization=both, activation=None)
    )
    (1): GraphConvLayer(
      (conv): GraphConv(in=512, out=512, normalization=both, activation=None)
    )
  )
  (bn_layers): ModuleList(
    (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (norms): ModuleList()
  (head): Sequential(
    (0): Linear(in_features=2560, out_features=1024, bias=True)
    (1): ReLU()
    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Dropout(p=0.2, inplace=False)
    (4): Linear(in_features=1024, out_features=7, bias=True)
  )
  (second_head): Linear(in_features=2048, out_features=7, bias=True)
)



























































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:11<00:00,  1.98it/s]























100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:48<00:00,  5.03it/s]

100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:49<00:00,  4.58it/s]
  0%|                                                                                                       | 0/500 [00:00<?, ?it/s]





























































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:14<00:00,  1.97it/s]























 99%|███████████████████████████████████████████████████████████████████████████████████████████▊ | 222/225 [00:48<00:00,  4.98it/s]

100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:49<00:00,  4.52it/s]
Saved best parameters at epoch 2




























































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:11<00:00,  1.99it/s]
























100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:49<00:00,  4.98it/s]

100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:50<00:00,  4.43it/s]
Saved best parameters at epoch 3




























































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:13<00:00,  1.97it/s]























100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:48<00:00,  4.98it/s]

100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:49<00:00,  4.53it/s]
Saved best parameters at epoch 4



























































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:11<00:00,  1.98it/s]























100%|████████████████████████████████████████████████████████████████████████████████████████████▌| 224/225 [00:48<00:00,  4.98it/s]

100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:49<00:00,  4.52it/s]
  0%|                                                                                                       | 0/500 [00:00<?, ?it/s]
Saved best parameters at epoch 5





























































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:13<00:00,  1.97it/s]
























100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:49<00:00,  4.52it/s]
EPOCH 6: Train acc: 89.21% Train Loss: 0.6465 Test acc: 74.52% Test Loss: 1.5552
Saved best parameters at epoch 6




























































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:10<00:00,  1.99it/s]
























100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:50<00:00,  5.03it/s]

100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:50<00:00,  4.42it/s]
Did not decrease test loss. Tolerance left 7





























































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:13<00:00,  1.98it/s]
























100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:49<00:00,  4.53it/s]
EPOCH 8: Train acc: 90.59% Train Loss: 0.5631 Test acc: 74.49% Test Loss: 1.5880




























































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:12<00:00,  1.98it/s]























100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:49<00:00,  4.53it/s]
  0%|                                                                                                       | 0/500 [00:00<?, ?it/s]
EPOCH 9: Train acc: 91.60% Train Loss: 0.5157 Test acc: 74.26% Test Loss: 1.5642




























































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:14<00:00,  1.97it/s]























100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:49<00:00,  4.55it/s]
EPOCH 10: Train acc: 91.69% Train Loss: 0.4974 Test acc: 74.69% Test Loss: 1.6223
  0%|                                                                                                       | 0/500 [00:00<?, ?it/s]
Saved best parameters at epoch 10



























































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:11<00:00,  1.99it/s]























100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:48<00:00,  5.03it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:49<00:00,  4.58it/s]
  0%|                                                                                                       | 0/500 [00:00<?, ?it/s]





























































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:14<00:00,  1.96it/s]























100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:48<00:00,  5.03it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:49<00:00,  4.53it/s]
  0%|                                                                                                       | 0/500 [00:00<?, ?it/s]




























































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:12<00:00,  1.98it/s]























100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:48<00:00,  5.03it/s]

100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:49<00:00,  4.53it/s]
Did not decrease test loss. Tolerance left 1





























































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:13<00:00,  1.98it/s]























 98%|██████████████████████████████████████████████████████████████████████████████████████████▉  | 220/225 [00:48<00:01,  4.98it/s]

100%|█████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:50<00:00,  4.48it/s]
Did not decrease test loss. Tolerance left 0
EARLY STOPPING AT ITERATION 14
SAVING RESULTS: experiment 1