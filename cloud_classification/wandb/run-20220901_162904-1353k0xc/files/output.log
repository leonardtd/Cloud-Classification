GraphClassifier(
  (cnn): CNNExtractor(
    (cnn): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (8): AdaptiveAvgPool2d(output_size=(1, 1))
    )
  )
  (graph_layers): ModuleList(
    (0): GraphConvLayer(
      (conv): GraphConv(in=2048, out=512, normalization=both, activation=None)
    )
    (1): GraphConvLayer(
      (conv): GraphConv(in=512, out=512, normalization=both, activation=None)
    )
  )
  (bn_layers): ModuleList(
    (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (head): Sequential(
    (0): Linear(in_features=2560, out_features=1024, bias=True)
    (1): ReLU()
    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Dropout(p=0.2, inplace=False)
    (4): Linear(in_features=1024, out_features=7, bias=True)
  )
  (second_head): Identity()
)
STARTING TRAINING: experiment 1


























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:55<00:00,  5.69it/s]








 98%|██████████████████████████████████████████████████████████████████████████████▉  | 275/282 [00:16<00:00, 17.23it/s]

100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:16<00:00, 16.59it/s]
Saved best parameters at epoch 1


























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:54<00:00,  5.73it/s]








 98%|███████████████████████████████████████████████████████████████████████████████▌ | 277/282 [00:16<00:00, 17.45it/s]

100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:17<00:00, 16.48it/s]
Saved best parameters at epoch 2


























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:54<00:00,  5.72it/s]








 98%|███████████████████████████████████████████████████████████████████████████████▌ | 277/282 [00:16<00:00, 17.31it/s]

100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:16<00:00, 16.66it/s]
Saved best parameters at epoch 3


























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:54<00:00,  5.69it/s]








 99%|████████████████████████████████████████████████████████████████████████████████▏| 279/282 [00:16<00:00, 17.48it/s]

100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:16<00:00, 16.77it/s]
Saved best parameters at epoch 4


























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:54<00:00,  5.72it/s]







 91%|█████████████████████████████████████████████████████████████████████████▊       | 257/282 [00:15<00:01, 17.19it/s]

100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:16<00:00, 16.73it/s]
Did not decrease test loss. Tolerance left 7



























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:54<00:00,  5.70it/s]







 93%|███████████████████████████████████████████████████████████████████████████▌     | 263/282 [00:15<00:01, 17.09it/s]

100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:16<00:00, 16.62it/s]
Saved best parameters at epoch 6


























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:54<00:00,  5.70it/s]








 92%|██████████████████████████████████████████████████████████████████████████▍      | 259/282 [00:15<00:01, 17.13it/s]

100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:17<00:00, 16.48it/s]
Saved best parameters at epoch 7


























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:54<00:00,  5.71it/s]








 95%|█████████████████████████████████████████████████████████████████████████████▎   | 269/282 [00:16<00:00, 16.96it/s]

100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:16<00:00, 16.61it/s]
Saved best parameters at epoch 8
Did not decrease test loss. Tolerance left 7


























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:54<00:00,  5.71it/s]








 95%|█████████████████████████████████████████████████████████████████████████████▎   | 269/282 [00:16<00:00, 17.10it/s]

100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:17<00:00, 16.56it/s]
Did not decrease test loss. Tolerance left 6


























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:54<00:00,  5.70it/s]








 97%|██████████████████████████████████████████████████████████████████████████████▍  | 273/282 [00:16<00:00, 16.92it/s]

100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:17<00:00, 16.57it/s]
Did not decrease test loss. Tolerance left 5


























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:54<00:00,  5.70it/s]








100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:16<00:00, 16.63it/s]
EPOCH 11: Train acc: 88.32% Train Loss: 0.3099 Test acc: 73.93% Test Loss: 0.8302
  0%|                                                                                           | 0/313 [00:00<?, ?it/s]



























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:54<00:00,  5.72it/s]








100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:17<00:00, 16.48it/s]
EPOCH 12: Train acc: 88.71% Train Loss: 0.3049 Test acc: 73.18% Test Loss: 0.8333
Did not decrease test loss. Tolerance left 3


























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:54<00:00,  5.71it/s]








 94%|████████████████████████████████████████████████████████████████████████████     | 265/282 [00:16<00:01, 16.91it/s]

100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:17<00:00, 16.48it/s]
Did not decrease test loss. Tolerance left 2


























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:54<00:00,  5.70it/s]








100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:16<00:00, 16.67it/s]
EPOCH 14: Train acc: 88.77% Train Loss: 0.2964 Test acc: 74.28% Test Loss: 0.7727
  0%|                                                                                           | 0/313 [00:00<?, ?it/s]



























100%|█████████████████████████████████████████████████████████████████████████████████| 313/313 [00:54<00:00,  5.72it/s]








100%|█████████████████████████████████████████████████████████████████████████████████| 282/282 [00:16<00:00, 16.64it/s]
EPOCH 15: Train acc: 88.98% Train Loss: 0.2904 Test acc: 74.62% Test Loss: 0.7800
Saved best parameters at epoch 15
Did not decrease test loss. Tolerance left 0
EARLY STOPPING AT ITERATION 15
SAVING RESULTS: experiment 1